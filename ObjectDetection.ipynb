{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importation des bibliothèques et chargement des classes YOLO"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "Dans cette cellule, nous importons les bibliothèques nécessaires pour le traitement d'images, OpenCV (cv2) et NumPy (np). \n",
        "Ensuite, nous chargeons les noms des classes à partir du fichier 'coco.names' qui contient les étiquettes des objets que le modèle YOLO est capable de détecter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Chargement des classes YOLO à partir du fichier 'coco.names'\n",
        "classes = None\n",
        "with open('coco.names', 'r') as f:\n",
        "    classes = [line.strip() for line in f.readlines()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Chargement du modèle YOLO et des poids pré-entraînés"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "Ici, nous chargeons le modèle YOLO à partir des fichiers 'yolov3.weights' et 'yolov3.cfg'. \n",
        "Ensuite, nous obtenons les noms des couches de sortie du modèle, qui seront utilisés pour extraire les prédictions de détection d'objets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Chargement du modèle YOLO et des poids pré-entraînés\n",
        "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')\n",
        "\n",
        "# Chargement des couches de sortie du modèle YOLO\n",
        "layer_names = net.getLayerNames() \n",
        "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Chargement de l'image et prétraitement"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "Cette cellule charge l'image que vous souhaitez détecter avec le modèle YOLO, puis elle la prétraite pour qu'elle soit compatible avec le modèle. \n",
        "Le modèle YOLO prend en entrée des images de taille 416x416 pixels, donc nous redimensionnons l'image et la convertissons en un \"blob\" qui est le format d'entrée attendu par le modèle YOLO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Chargement de l'image à détecter\n",
        "image = cv2.imread('image.jpg')\n",
        "height, width, channels = image.shape\n",
        "\n",
        "# Prétraitement de l'image pour l'entrée du modèle YOLO\n",
        "blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "net.setInput(blob)\n",
        "outs = net.forward(output_layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analyse des détections"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        " Cette cellule parcourt les sorties du réseau de neurones pour extraire les boîtes englobantes, les confiances et les identifiants de classe des détections d'objets.\n",
        " Nous conservons seulement les détections dont la confiance est supérieure à un seuil défini (dans ce cas, 0.5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Initialisation de listes pour les boîtes englobantes, les confidences et les classes détectées\n",
        "boxes = []\n",
        "confidences = []\n",
        "class_ids = []\n",
        "\n",
        "# Analyse des détections\n",
        "for out in outs:\n",
        "    for detection in out:\n",
        "        scores = detection[5:]\n",
        "        class_id = np.argmax(scores)\n",
        "        confidence = scores[class_id]\n",
        "        if confidence > 0.5:\n",
        "            # Coordonnées de la boîte englobante\n",
        "            center_x = int(detection[0] * width)\n",
        "            center_y = int(detection[1] * height)\n",
        "            w = int(detection[2] * width)\n",
        "            h = int(detection[3] * height)\n",
        "\n",
        "            # Coordonnées de la boîte englobante (coin supérieur gauche)\n",
        "            x = int(center_x - w / 2)\n",
        "            y = int(center_y - h / 2)\n",
        "\n",
        "            boxes.append([x, y, w, h])\n",
        "            confidences.append(float(confidence))\n",
        "            class_ids.append(class_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suppression des détections multiples et affichage des résultats"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "Cette cellule utilise la méthode de suppression non-maximale pour éliminer les détections redondantes et ne conserver que les détections les plus fiables.\n",
        "Ensuite, elle affiche les boîtes englobantes des objets détectés avec leur étiquette sur l'image d'origine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Suppression des détections multiples et application de la non-maxima suppression\n",
        "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "\n",
        "# Affichage des détections sur l'image\n",
        "font = cv2.FONT_HERSHEY_PLAIN\n",
        "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "for i in range(len(boxes)):\n",
        "    if i in indexes:\n",
        "        x, y, w, h = boxes[i]\n",
        "        label = str(classes[class_ids[i]])\n",
        "        color = colors[i]\n",
        "        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
        "        cv2.putText(image, label, (x, y + 30), font, 3, color, 3)\n",
        "\n",
        "# Affichage de l'image avec les détections\n",
        "cv2.imshow(\"Image\", image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
